{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:25:25.160261Z",
     "iopub.status.busy": "2025-01-16T16:25:25.159720Z",
     "iopub.status.idle": "2025-01-16T16:27:17.459481Z",
     "shell.execute_reply": "2025-01-16T16:27:17.457966Z",
     "shell.execute_reply.started": "2025-01-16T16:25:25.160214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -U bitsandbytes\n",
    "# !pip install -q git+https://github.com/gmihaila/ml_things.git\n",
    "!pip install trl\n",
    "!pip install arabert\n",
    "!pip install wandb\n",
    "# !pip install shap\n",
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:27:17.462099Z",
     "iopub.status.busy": "2025-01-16T16:27:17.461620Z",
     "iopub.status.idle": "2025-01-16T16:27:46.681315Z",
     "shell.execute_reply": "2025-01-16T16:27:46.679877Z",
     "shell.execute_reply.started": "2025-01-16T16:27:17.462061Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import evaluate\n",
    "from transformers import (GPT2Tokenizer,\n",
    "                          AutoTokenizer,\n",
    "                          GPT2LMHeadModel,\n",
    "                          AutoModelForSequenceClassification,\n",
    "                          AutoModelForCausalLM,\n",
    "                          TrainingArguments,\n",
    "                          Trainer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          pipeline,\n",
    "                          logging)\n",
    "from transformers import logging as hf_logging\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from trl import SFTTrainer\n",
    "# from trl import setup_chat_format\n",
    "\n",
    "# import bitsandbytes\n",
    "import os\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             f1_score,\n",
    "                             classification_report,\n",
    "                             confusion_matrix,\n",
    "                             auc)\n",
    "\n",
    "from huggingface_hub import login\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize, rgb2hex\n",
    "from matplotlib.ticker import PercentFormatter \n",
    "from IPython.display import HTML\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"pytorch version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:27:46.684683Z",
     "iopub.status.busy": "2025-01-16T16:27:46.683957Z",
     "iopub.status.idle": "2025-01-16T16:27:46.691893Z",
     "shell.execute_reply": "2025-01-16T16:27:46.690446Z",
     "shell.execute_reply.started": "2025-01-16T16:27:46.684648Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value)  # CPU vars\n",
    "    torch.manual_seed(seed_value)  # CPU vars\n",
    "    random.seed(seed_value)  # Python random seed\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  # GPU vars\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def format_duration(total_time):\n",
    "    time_delta = timedelta(seconds=total_time)\n",
    "    hours, remainder = divmod(time_delta.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return \"{} hours, {} minutes, {} seconds\".format(hours, minutes, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:27:46.693769Z",
     "iopub.status.busy": "2025-01-16T16:27:46.693471Z",
     "iopub.status.idle": "2025-01-16T16:27:46.745840Z",
     "shell.execute_reply": "2025-01-16T16:27:46.744639Z",
     "shell.execute_reply.started": "2025-01-16T16:27:46.693744Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    " # Set the seed\n",
    "SEED = 42\n",
    "random_seed(SEED, torch.cuda.is_available())\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:40:18.483726Z",
     "iopub.status.busy": "2025-01-16T16:40:18.483247Z",
     "iopub.status.idle": "2025-01-16T16:40:18.498047Z",
     "shell.execute_reply": "2025-01-16T16:40:18.496665Z",
     "shell.execute_reply.started": "2025-01-16T16:40:18.483697Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "class HardDataset:\n",
    "    def __init__(self, data_path, seed=42, use_subset=False):\n",
    "        \"\"\"\n",
    "        Initializes the dataset class.\n",
    "        \n",
    "        Args:\n",
    "            data_path (str): The path to the dataset file.\n",
    "            seed (int): Random seed for reproducibility.\n",
    "            use_subset (bool): Whether to use a subset of the dataset or the entire dataset.\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.seed = seed\n",
    "        self.use_subset = use_subset\n",
    "        self.df = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load the data from a TSV file and retain only the 'rating' and 'review' columns.\n",
    "        Also, transform the 'rating' to a binary label (positive/negative).\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: The loaded and preprocessed DataFrame.\n",
    "        \"\"\"\n",
    "        # Load the dataset\n",
    "        self.df = pd.read_csv(self.data_path, delimiter='\\t')\n",
    "\n",
    "        # Keep only 'rating' and 'review' columns\n",
    "        self.df = self.df[['rating', 'review']]\n",
    "\n",
    "        # Code rating: positive (1) if rating > 3, negative (0) if rating < 3\n",
    "        self.df['rating'] = self.df['rating'].apply(lambda x: 0 if x < 3 else 1)\n",
    "\n",
    "        # Rename columns for consistency with standard text classification format\n",
    "        self.df.columns = ['label', 'text']\n",
    "        print(f\"Initial dataset length: {len(self.df)}\")\n",
    "\n",
    "        # Apply the subset logic if needed\n",
    "        if self.use_subset:\n",
    "            self.df = self.filter_and_sample_data(self.df)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "    def filter_and_sample_data(self, df):\n",
    "        \"\"\"\n",
    "        Filter and sample the dataset based on word count and class balance.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): The full dataset before filtering.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: The filtered and balanced DataFrame.\n",
    "        \"\"\"\n",
    "        print(\"\\nFiltering dataset based on word count and label balance...\")\n",
    "        # Remove instances with word count greater than 100\n",
    "        df[\"word_count\"] = df['text'].apply(lambda x: len(x.split()))\n",
    "        df = df[df['word_count'] < 100]\n",
    "        print(f\"Dataset length after word count filter: {len(df)}\")\n",
    "\n",
    "        # Limit samples per label to max_samples\n",
    "        max_samples = 7000\n",
    "        df_sampled = df.groupby(\"label\")[[\"text\", \"label\"]].apply(\n",
    "            lambda x: x.sample(n=min(len(x), max_samples))\n",
    "        )\n",
    "        df_sampled = df_sampled.reset_index(drop=True)\n",
    "\n",
    "        print(f\"Dataset length after class balancing: {len(df_sampled)}\")\n",
    "        return df_sampled\n",
    "\n",
    "    def analyze_data(self):\n",
    "        \"\"\"\n",
    "        Perform exploratory data analysis on the dataset.\n",
    "        This includes visualizing label distribution and word count distribution.\n",
    "        \"\"\"\n",
    "        if self.df is None:\n",
    "            raise ValueError(\"Data not loaded. Please call 'load_data()' first.\")\n",
    "\n",
    "        # Show label distribution\n",
    "        label_counts = self.df['label'].value_counts()\n",
    "        print(\"\\nLabel Distribution:\")\n",
    "        print(label_counts)\n",
    "\n",
    "        # Visualize label distribution\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"viridis\")\n",
    "        plt.title(\"Label Distribution\")\n",
    "        plt.xlabel(\"Label\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "        plt.show()\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"\n",
    "        Split the dataset into train, validation, and test sets.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Train, validation, and test datasets as separate DataFrames.\n",
    "        \"\"\"\n",
    "        # Split the data into train, validation, and test sets\n",
    "        train_df, temp_df = train_test_split(self.df, test_size=0.2, random_state=self.seed)\n",
    "        val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=self.seed)\n",
    "\n",
    "        print(f\"Train shape: {train_df.shape}\")\n",
    "        print(f\"Validation shape: {val_df.shape}\")\n",
    "        print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "        return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:10.229488Z",
     "iopub.status.busy": "2025-01-16T16:41:10.229191Z",
     "iopub.status.idle": "2025-01-16T16:41:11.816401Z",
     "shell.execute_reply": "2025-01-16T16:41:11.815123Z",
     "shell.execute_reply.started": "2025-01-16T16:41:10.229462Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset length: 105698\n",
      "\n",
      "Filtering dataset based on word count and label balance...\n",
      "Dataset length after word count filter: 103804\n",
      "Dataset length after class balancing: 14000\n",
      "\n",
      "Label Distribution:\n",
      "label\n",
      "0    7000\n",
      "1    7000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (11200, 2)\n",
      "Validation shape: (1400, 2)\n",
      "Test shape: (1400, 2)\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"data/arabic-sa-hard-dataset/balanced-reviews-utf8.tsv\"\n",
    "# Initialize the dataset class\n",
    "# To use the whole dataset set use_subset to False\n",
    "dataset = HardDataset(data_path=DATASET_PATH, seed=42, use_subset=True)\n",
    "\n",
    "# Load data\n",
    "df = dataset.load_data()\n",
    "\n",
    "# Optionally analyze the data\n",
    "dataset.analyze_data()\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_df, val_df, test_df = dataset.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:11.819215Z",
     "iopub.status.busy": "2025-01-16T16:41:11.818790Z",
     "iopub.status.idle": "2025-01-16T16:41:11.828576Z",
     "shell.execute_reply": "2025-01-16T16:41:11.827199Z",
     "shell.execute_reply.started": "2025-01-16T16:41:11.819186Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_prompt(text: str, label: str = None):\n",
    "    # Formulate the text with a specific instruction for classification\n",
    "    prompt = \"\"\"\n",
    "You will be given an Arabic hotel review. Your task is to classify it as one of the labels in the list: positive, negative. Output the label only, and nothing else.\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "Answer: {label}\n",
    "\"\"\".strip()\n",
    "    return prompt.format(text=text, label=label)\n",
    "\n",
    "# Mapping dictionary\n",
    "def create_dataset(df):\n",
    "    \"\"\"\n",
    "    Create a dataset for training, validation, or testing.\n",
    "    If is_test=True, exclude the label from the prompt.\n",
    "    If not, map the raw labels (0, 1) to strings ('negative', 'positive').\n",
    "    \"\"\"\n",
    "    label_map = {1: \"positive\", 0: \"negative\"}\n",
    "    rows = []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        label = label_map[row.label]  # Map raw labels to strings\n",
    "        rows.append(\n",
    "            {\n",
    "                \"input\": create_prompt(row.text, label),\n",
    "                \"output\": label \n",
    "            }\n",
    "        )\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:11.830645Z",
     "iopub.status.busy": "2025-01-16T16:41:11.830327Z",
     "iopub.status.idle": "2025-01-16T16:41:12.870251Z",
     "shell.execute_reply": "2025-01-16T16:41:12.868541Z",
     "shell.execute_reply.started": "2025-01-16T16:41:11.830620Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11200it [00:00, 14524.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given an Arabic hotel review. Your task is to classify it as one of the labels in the list: positive, negative. Output the label only, and nothing else.\n",
      "<text>\n",
      "“فندق رائع”. تعاون الموظفين كان رائعا كان لي بعض التعليقات على مستوى الاثاث ولكن ادارة الفندق اسرعت بتغير كل ما يلزم في الغرفه مع الكرم الاضافي بلا مقابل المدير متعاون الى ابعد درجه. بعض اثاث الغرفه يحتاج الى تغير ككراسي الضيافه المصاعد لم تكن كلها تعمل مما تسبب في الزحام والتكدس الزائد عند كل صلاه\n",
      "</text>\n",
      "Answer: positive \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [00:00, 14942.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given an Arabic hotel review. Your task is to classify it as one of the labels in the list: positive, negative. Output the label only, and nothing else.\n",
      "<text>\n",
      "ضعيف جداً. . لا يستحق 5 نجوم\n",
      "</text>\n",
      "Answer: negative \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_pandas_test['label'] = df_pandas_test['label'].replace({1: 'positive', 0: 'negative'})\n",
    "train_rows = create_dataset(train_df)\n",
    "Path(\"hard_train_data.json\").write_text(json.dumps(train_rows))\n",
    "print(train_rows[0][\"input\"], \"\\n\")\n",
    "\n",
    "dev_rows = create_dataset(val_df)\n",
    "Path(\"hard_dev_data.json\").write_text(json.dumps(dev_rows))\n",
    "print(dev_rows[1][\"input\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:12.872796Z",
     "iopub.status.busy": "2025-01-16T16:41:12.872330Z",
     "iopub.status.idle": "2025-01-16T16:41:13.033841Z",
     "shell.execute_reply": "2025-01-16T16:41:13.032333Z",
     "shell.execute_reply.started": "2025-01-16T16:41:12.872756Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [00:00, 10521.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given an Arabic hotel review. Your task is to classify it as one of the labels in the list: positive, negative. Output the label only, and nothing else.\n",
      "<text>\n",
      "“الموقع ممتاز اكن الغرفة صغيره جدا”. موقع مميز قريب من الحرم دقائق معدودة والفندق نظيف والاثاث يعتبر جديد. غرفه صغيره جدا الباب لم يفتح بالبطاقه الذكيه كل مره ندخل فيها للغرفة لا يفتح الباب لمدة يومين ونتظطر للانتظار والنزول للاستقبال ولا يفتح الا بالمستر كي وخدمة حامل الحقائب تأخر علينا ونزلت وانا احمل جميع حقائبي وغير ذلك لا يوجد ملاحظات\n",
      "</text>\n",
      "Answer: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(text: str, label: str = None):\n",
    "    # Formulate the text with a specific instruction for classification\n",
    "    prompt = \"\"\"\n",
    "You will be given an Arabic hotel review. Your task is to classify it as one of the labels in the list: positive, negative. Output the label only, and nothing else.\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    "    return prompt.format(text=text, label=label)\n",
    "    \n",
    "test_rows = create_dataset(test_df)\n",
    "Path(\"hard_test_data.json\").write_text(json.dumps(test_rows))\n",
    "\n",
    "print(test_rows[0][\"input\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading and Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:42:56.693447Z",
     "iopub.status.busy": "2025-01-16T16:42:56.693073Z",
     "iopub.status.idle": "2025-01-16T16:42:56.707622Z",
     "shell.execute_reply": "2025-01-16T16:42:56.706013Z",
     "shell.execute_reply.started": "2025-01-16T16:42:56.693419Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Configuration Functions ---\n",
    "def setup_tokenizer(model_id: str):\n",
    "    \"\"\"Sets up the tokenizer for the model.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    print(\"Vocabulary size:\", len(tokenizer))\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer\n",
    "\n",
    "def setup_quantization():\n",
    "    \"\"\"Sets up the quantization configuration.\"\"\"\n",
    "    nf4_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True, # Enables 4-bit quantization of the base model to reduce memory usage.\n",
    "        bnb_4bit_quant_type=\"nf4\", #  The quantization type (\"nf4\" is a common choice)\n",
    "        bnb_4bit_use_double_quant=True, # Enables nested quantization (double quantization) for further memory reduction.\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16 # Specifies the data type for computations during training (float16 in this case).\n",
    "    )\n",
    "    return nf4_config\n",
    "\n",
    "def setup_model(model_id: str, nf4_config):\n",
    "    \"\"\"Loads the model with quantization and configuration.\"\"\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=nf4_config\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    return model\n",
    "\n",
    "def setup_lora(modules):\n",
    "    \"\"\"Sets up the LoRA configuration.\"\"\"\n",
    "    lora_config = LoraConfig(\n",
    "        r=64,  # 8\n",
    "        lora_alpha=16, \n",
    "        target_modules=modules, # check target_modules for any model (see function target_modules)\n",
    "        lora_dropout=0.1, # 0.05 increase (e.g., 0.2-0.3) for small datasets or noisy data.\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\"\n",
    "    )\n",
    "    return lora_config\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"Prints the number of trainable parameters in the model.\"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"Trainable params: {trainable_params} || Total params: {all_param} || Trainable%: {100 * trainable_params / all_param:.2f}\")\n",
    "\n",
    "# --- Main Training Function ---\n",
    "\n",
    "def train_model(model, task: str, modules, train_dataset, val_dataset):\n",
    "    \"\"\"Handles the entire training process.\"\"\"\n",
    "    os.environ[\"WANDB_PROJECT\"] = f\"model_name{task}\"\n",
    "    os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "    # Apply LoRA\n",
    "    model.enable_input_require_grads()\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    print_trainable_parameters(model)\n",
    "    model = model.to(device)\n",
    "    model.hf_device_map\n",
    "\n",
    "    # Create Trainer instance\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        args = SFTConfig(\n",
    "            dataset_text_field =\"input\",\n",
    "            # max_seq_length=512,\n",
    "            output_dir=f\"model_name{task}\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\", \n",
    "            # eval_steps = 0.2\n",
    "            learning_rate=2e-4, # 2e-5 learning rate, based on QLoRA paper 2e-4\n",
    "            per_device_train_batch_size=4, #\n",
    "            per_device_eval_batch_size=4,\n",
    "            gradient_accumulation_steps=1,            # number of steps before performing a backward/update pass\n",
    "            # gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "            optim=\"paged_adamw_32bit\",\n",
    "            fp16=True,\n",
    "            bf16=False,\n",
    "            num_train_epochs=3, \n",
    "            weight_decay=0.001, # Lower (e.g., 0.001) if underfitting or noisy datasets.\n",
    "            max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "            max_steps=-1,\n",
    "            # group_by_length=False,\n",
    "            lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "            warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "            logging_dir=\"./logs\",\n",
    "            logging_steps=50, # try 1\n",
    "            report_to=\"wandb\",\n",
    "            push_to_hub=True,\n",
    "            packing=False,\n",
    "        ),\n",
    "        peft_config=lora_config,\n",
    "        # dataset_kwargs={\n",
    "        #     \"add_special_tokens\": False,\n",
    "        #     \"append_concat_token\": False\n",
    "        # }\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Training completed in {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Building the model\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    login(token=\"your_hf\") # write token\n",
    "    !wandb login your_wandb_token\n",
    "    model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    task = \"ASA\" # Arabic Sentiment Analysis\n",
    "\n",
    "    train_dataset = Dataset.from_list(train_rows)\n",
    "    dev_dataset = Dataset.from_list(dev_rows)\n",
    "\n",
    "    tokenizer = setup_tokenizer(model_id)\n",
    "    nf4_config = setup_quantization()\n",
    "    model = setup_model(model_id, nf4_config)\n",
    "    model = model.to(device)\n",
    "    modules = find_all_linear_names(model)\n",
    "    lora_config = setup_lora(modules)\n",
    "    # train_model(p_model, task, formatting_prompts_func_sst2, modules)\n",
    "    train_model(model, task, modules, train_dataset, dev_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load finetuned model from huggingface\n",
    "login(token=\"your_hf_token\") \n",
    "model_id = \"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "nf4_config = setup_quantization()\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=nf4_config\n",
    "        ).to(device)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# One instance\n",
    "%%time\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "inp_test = test_rows[0][\"input\"]\n",
    "messages = [{\"role\": \"user\", \"content\": inp_test}]\n",
    "content = messages[0][\"content\"]\n",
    "inputs = tokenizer(content, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=1, temperature=0.000001, pad_token_id=tokenizer.eos_token_id)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "parts = [part.strip() for part in generated_text.split(\"Answer:\") if part.strip()]\n",
    "\n",
    "\n",
    "regex = r\"^\\W+|\\W+$\"\n",
    "prediction = re.sub(regex, \"\", parts[-1])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "predictions = []\n",
    "true_values = []\n",
    "for row in tqdm(test_rows):\n",
    "    messages = [{\"role\": \"user\", \"content\": row[\"input\"]}]\n",
    "    content = messages[0][\"content\"]\n",
    "    inputs = tokenizer(content, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=1, temperature=0.000001, pad_token_id=tokenizer.eos_token_id)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    parts = [part.strip() for part in generated_text.split(\"Answer:\") if part.strip()]\n",
    "    predictions.append(parts[-1])\n",
    "    true_values.append(row[\"output\"])\n",
    "\n",
    "regex = r\"^\\W+|\\W+$\"\n",
    "predictions = [re.sub(regex, \"\", p) for p in predictions]\n",
    "len(true_values), len(predictions)\n",
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# if the model generated classes that doesn't exist\n",
    "class_names = ['positive', 'negative']\n",
    "eval_df = pd.DataFrame().from_dict({\"label\":true_values, \"prediction\":predictions})\n",
    "len(eval_df[~eval_df.prediction.isin(class_names)]) # check ...\n",
    "eval_df = eval_df[eval_df.prediction.isin(class_names)] # remove if len > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(true_values, predictions))\n",
    "print(classification_report(eval_df.label, eval_df.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(eval_df.label, eval_df.prediction, labels=class_names)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5053607,
     "sourceId": 8474503,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
